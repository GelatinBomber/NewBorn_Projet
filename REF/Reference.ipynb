{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["sonV-7RsBzD7","FROO8Y0EBq7a","HFaCSJDYeDCN","dgDxPVjcIX-1","udDtws0vT-HC","3ofQs7YHTerj"],"authorship_tag":"ABX9TyMMqlipLMzC+gqspbp1057+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kCzwI4_qkV8F"},"outputs":[],"source":["# slicing function\n","def x_slicing(delta,s1,s2,s3):\n","    x = np.float32(data[s1:s1+delta,1:-1])\n","    x = np.append(x,np.float32(data[s2:s2+delta,1:-1]),0)\n","    x = np.append(x,np.float32(data[s3:s3+delta,1:-1]),0)\n","                                                    # axis=0\n","    return x\n","\n","def y_slicing(delta,s1,s2,s3)\n","    y = data[s1:s1+delta,[-1]]\n","    y = np.append(y,data[s2:s2+delta,[-1]],0)\n","    y = np.append(y,data[s3:s3+delta,[-1]],0)\n","    return y"]},{"cell_type":"code","source":["# 회귀 계수 출력\n","print('Weight =', W.numpy())\n","print('Bias =', b.numpy())"],"metadata":{"id":"acc5wdwMj0_K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prepare Development Environment"],"metadata":{"id":"sonV-7RsBzD7"}},{"cell_type":"code","source":["# import Library\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","tf.random.set_seed(5)"],"metadata":{"id":"Os5jmaCy8tMk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Colab data upload\n","from google.colab import files\n","uploaded = files.upload()"],"metadata":{"id":"paGSPwAFBox-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set seed\n","tf.random.set_seed(5)"],"metadata":{"id":"V4gBMp96HpO8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Load\n"],"metadata":{"id":"FROO8Y0EBq7a"}},{"cell_type":"code","source":["# 데이터 준비\n","data_set = np.loadtxt(\"abc_wave_counting2.csv\", delimiter=\",\",skiprows=1)\n","x = data_set[:,0:-1]\n","y = data_set[:,-1]"],"metadata":{"id":"6hdCKBCNXRvG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 준비 : str로 불러오기\n","data_set = np.loadtxt('abc_wave_counting.csv',delimiter=',',dtype=np.str_)\n","\n","# x\n","x = data_set[:,0:-1]\n","x = np.float32(x)\n","\n","# y\n","y = data_set[:,-1]\n","y = np.float32(y)\n","\n","print(x[0])"],"metadata":{"id":"7HPXQ8TEXWBX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 준비 : pandas 이용\n","Data_set = pd.read_csv('abc_wave_counting.csv')\n","Data_set.head()"],"metadata":{"id":"i69-S3VNXoCq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model with keras"],"metadata":{"id":"HFaCSJDYeDCN"}},{"cell_type":"code","source":["# 딥러닝 모델의 구조를 결정합니다.\n","model = Sequential()\n","model.add(Dense(30, input_dim=16, activation ='relu'))\n","model.add(Dense(1,))"],"metadata":{"id":"Rhe5v4UzePLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 딥러닝 모델을 실행합니다.\n","model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","history = model.fit(x, y, epochs=50, batch_size=16)"],"metadata":{"id":"9wh-D0V7eRpz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Layer"],"metadata":{"id":"dgDxPVjcIX-1"}},{"cell_type":"code","source":["# class의 개수 설정\n","nb_classes = 10"],"metadata":{"id":"SZG79VPHSa73"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 퍼셉트론(Perceptron) 개수 정하기\n","percep1 = 512\n","percep2 = 512\n","percep3 = 512"],"metadata":{"id":"-mZcvE6uQz-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Layer 1 : Hidden Layer\n","\n","# Weight & Bias\n","W1 = tf.Variable(tf.random.normal([784,percep1]), name='weight1')\n","b1 = tf.Variable(tf.random.normal([percep1]), name='bias1')\n","\n","def layer1(X):\n","    return  tf.nn.relu(tf.matmul(X,W1) + b1 )"],"metadata":{"id":"BFCdFKfWIgsW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Layer 2 : Hidden Layer\n","\n","# Weight & Bias\n","W2 = tf.Variable(tf.random.normal([percep1,percep2]), name='weight2')\n","b2 = tf.Variable(tf.random.normal([percep2]), name='bias2')\n","\n","def layer2(X):\n","    return  tf.nn.relu(tf.matmul(layer1(X),W2) + b2 )"],"metadata":{"id":"j3t39OrhQb6D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Layer 3 : Hidden Layer\n","\n","# Weight & Bias\n","W3 = tf.Variable(tf.random.normal([percep2,percep3]), name='weight3')\n","b3 = tf.Variable(tf.random.normal([percep3]), name='bias3')\n","\n","def layer3(X):\n","    return  tf.nn.relu(tf.matmul(layer2(X),W3) + b3 )"],"metadata":{"id":"XfppceKbQdg8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Layer 4 : Output Layer\n","\n","# Weight & Bias\n","W4 = tf.Variable(tf.random.normal([percep3,nb_classes]), name='weight4')\n","b4 = tf.Variable(tf.random.normal([nb_classes]), name='bias4')\n","\n","# inner product\n","def logits(X):\n","    return tf.matmul(layer3(X),W4) + b4\n","\n","# Softmax function\n","def hypothesis(X):\n","    return tf.nn.softmax(logits(X))"],"metadata":{"id":"54nIu49XQfM6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Linear Regression\n","def hypothesis(X) :\n","    return tf.matmul(layer2(X),W3) + b3"],"metadata":{"id":"Ny2nTfOkTEdn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gradient descent"],"metadata":{"id":"udDtws0vT-HC"}},{"cell_type":"code","source":["# 경사 하강법(Gradient descent)\n","optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)"],"metadata":{"id":"xTl-1GNFH9eu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Learn"],"metadata":{"id":"3ofQs7YHTerj"}},{"cell_type":"code","source":["# 학습 시작\n","\n","# batch 사이즈로 나누어 학습, 효율적이며 시간 단축\n","training_epoch =15\n","batch_size = 600\n","\n","print('*'*5,'Start Learnimg!!')\n","for epoch in range(training_epoch):\n","\n","    avg_cost = 0\n","\n","    # 100 = 60,000 / 600\n","    total_batch = int(x_train.shape[0]/batch_size)\n","    for k in range(total_batch): # 100 회\n","        batch_xs = x_train[k*batch_size:(1+k)*batch_size]\n","        batch_ys = Y_one_hot[k*batch_size:(1+k)*batch_size]\n","\n","        # 비용 함수\n","        def cost_func_batch():\n","            cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits(batch_xs),\n","                                                         labels=batch_ys)\n","                                                            # y_train 에서 Y_one_hot 으로\n","            cost = tf.reduce_mean(cost_i)\n","            return cost\n","\n","        # 학습 시작\n","        optimizer.minimize(cost_func_batch,var_list=[W1,W2,W3,W4,b1,b2,b3,b4])\n","\n","\n","        # 누적 비용\n","        avg_cost += cost_func_batch().numpy()/total_batch\n","    print('Epoch:','%04d'%(epoch + 1),'cost:','{:.9f}'.format(avg_cost))\n","\n","print('*'*5,'Learnimg Finished!!')"],"metadata":{"id":"9Wq9r9ICTufk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a1bEB5A9jzkP"},"execution_count":null,"outputs":[]}]}
