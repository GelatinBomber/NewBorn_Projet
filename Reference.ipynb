{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TyRk_YyIAKsF",
        "sonV-7RsBzD7",
        "FROO8Y0EBq7a",
        "QgIdjLjQib-J",
        "gv7pMO6_eVJx",
        "_-hVBDW0NfhV",
        "b5Y9qnwYWYsA",
        "8fa2QynwZKi8",
        "UNcAyCF9mUpP",
        "OB_EquWi0NFt",
        "9tLgrJHlDhZB",
        "aMI6CpS-vwqx",
        "DpA7RMcMvzVS",
        "x_Jnh4QNTGFQ",
        "dgDxPVjcIX-1"
      ],
      "authorship_tag": "ABX9TyNkzxyZnqv9vcC96LQzYiDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GelatinBomber/NewBorn_Projet/blob/main/Reference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Reference"
      ],
      "metadata": {
        "id": "TyRk_YyIAKsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([ ])\n",
        "x.dtype"
      ],
      "metadata": {
        "id": "8-C-GC3fARWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [00] Preparing Development Environment"
      ],
      "metadata": {
        "id": "sonV-7RsBzD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## [00] Preparing Development Environment"
      ],
      "metadata": {
        "id": "-hd2lWpMjNLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import Library\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Os5jmaCy8tMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab data upload\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "paGSPwAFBox-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed\n",
        "tf.random.set_seed(5)"
      ],
      "metadata": {
        "id": "V4gBMp96HpO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import Library from tf.keras\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense"
      ],
      "metadata": {
        "id": "HrBDd9jliWFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [01] Data Load\n"
      ],
      "metadata": {
        "id": "FROO8Y0EBq7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## [01] Data Load"
      ],
      "metadata": {
        "id": "kpkx2ysQjJzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data load\n",
        "data_set = np.loadtxt(\"abc_wave_counting2.csv\", delimiter=\",\",skiprows=1,dtype=np.float32)\n",
        "x = data_set[:,:-1]\n",
        "y = data_set[:,-1]\n",
        "\n",
        "(row,column) = x.shape"
      ],
      "metadata": {
        "id": "6hdCKBCNXRvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 준비 : str로 불러오기\n",
        "data_set = np.loadtxt('abc_wave_counting.csv',delimiter=',',dtype=np.str_)\n",
        "\n",
        "# x\n",
        "x = data_set[:,:-1]\n",
        "x = np.float32(x)\n",
        "\n",
        "# y\n",
        "y = data_set[:,-1]\n",
        "y = np.float32(y)\n",
        "\n",
        "print(x[0])"
      ],
      "metadata": {
        "id": "7HPXQ8TEXWBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 준비 : pandas 이용\n",
        "Data_set = pd.read_csv('abc_wave_counting.csv')\n",
        "Data_set.head()"
      ],
      "metadata": {
        "id": "i69-S3VNXoCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [02] Data Preprocessing"
      ],
      "metadata": {
        "id": "QgIdjLjQib-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## [02] Data Preprocessing"
      ],
      "metadata": {
        "id": "mBymzNG-jEld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing function\n",
        "def x_slicing(delta,s1,s2,s3):\n",
        "    x = np.float32(data[s1:s1+delta,1:-1])\n",
        "    x = np.append(x,np.float32(data[s2:s2+delta,1:-1]),0)\n",
        "    x = np.append(x,np.float32(data[s3:s3+delta,1:-1]),0)\n",
        "    return x\n",
        "\n",
        "def y_slicing(delta,s1,s2,s3):\n",
        "    y = data[s1:s1+delta,[-1]]\n",
        "    y = np.append(y,data[s2:s2+delta,[-1]],0)\n",
        "    y = np.append(y,data[s3:s3+delta,[-1]],0)\n",
        "    return y"
      ],
      "metadata": {
        "id": "Wty60SlxiemV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encording\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=3)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=3)"
      ],
      "metadata": {
        "id": "QepWXn_hilbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train\n",
        "x_train = np.float32(data[:35,1:-1])\n",
        "x_train = np.append(x_train,np.float32(data[50:85,1:-1]),0)\n",
        "x_train = np.append(x_train,np.float32(data[100:135,1:-1]),0)\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "5D5HIxjURAZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 정규화(Normalization) : 0 to 255 ==> 0 to 1\n",
        "# Z = (X-min())/(max()-min())\n",
        "def normalizer(data):\n",
        "    result = (data - np.min(data,axis=0))/(np.max(data,axis=0) - np.min(data,axis=0))\n",
        "                            # column 방향으로 비교\n",
        "    return result\n",
        "\n",
        "# print(np.min(x_train,axis=0))   # 0  ...\n",
        "# print(np.max(x_train,axis=0))   # 255 ...\n",
        "# x_train = normalizer(x_train)\n",
        "# x_test = nomalizer(x_test)"
      ],
      "metadata": {
        "id": "Ml-iLo_5nqMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensional transformation\n",
        "x_train = tf.reshape(x_train,[-1,28,28,1])  # 4 dimension\n",
        "x_test = tf.reshape(x_test,[-1,28,28,1])    # 4 dimension\n",
        "print(x_train.shape,x_train.dtype)\n",
        "print(x_test.shape,x_test.dtype)"
      ],
      "metadata": {
        "id": "8w6PebjTn5E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of Data"
      ],
      "metadata": {
        "id": "IxxXKNJznn0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Shape of data\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "w6ld0mTIn7NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing Shape of data\n",
        "x_train = tf.reshape(x_train,[-1,28,28,1])"
      ],
      "metadata": {
        "id": "PqsYFy5Mnv9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type of value"
      ],
      "metadata": {
        "id": "CBdsnRuTng_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Type of value\n",
        "print(x_train.dtype)"
      ],
      "metadata": {
        "id": "ujsnEE-lEdIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing Type of value\n",
        "x_train = tf.cast(x_train,dtype=tf.float32)"
      ],
      "metadata": {
        "id": "x8p4ZzVjEtMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [03] Model implement"
      ],
      "metadata": {
        "id": "gv7pMO6_eVJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [0] Model implement"
      ],
      "metadata": {
        "id": "_-hVBDW0NfhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## [03] Model implement"
      ],
      "metadata": {
        "id": "sw3tbFmJVw29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model implement\n",
        "model = tf.keras.Sequential([\n",
        "\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "# param : 변수 = n*m + m"
      ],
      "metadata": {
        "id": "i2sB17ZTecTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_shape\n",
        "input_shape=(column,)"
      ],
      "metadata": {
        "id": "nZRToGXg6XtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# activation\n",
        "activation='relu'\n",
        "activation='softmax'"
      ],
      "metadata": {
        "id": "AC44dhGdqCAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [1] Dense Layers"
      ],
      "metadata": {
        "id": "b5Y9qnwYWYsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) Dense Layer"
      ],
      "metadata": {
        "id": "-ml3PPSB565v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.Dense(units=4,activation='relu')"
      ],
      "metadata": {
        "id": "b5cHOnLvothl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) Flatten Layer"
      ],
      "metadata": {
        "id": "PR0Rv6586g_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.Flatten()"
      ],
      "metadata": {
        "id": "K4YBrjptoYv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) Dropout Layer"
      ],
      "metadata": {
        "id": "J6f79EaV6oCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.Dropout(0.3)"
      ],
      "metadata": {
        "id": "cpXReGjePQrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [2] CNN Layers"
      ],
      "metadata": {
        "id": "8fa2QynwZKi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) Conv2D Layer"
      ],
      "metadata": {
        "id": "hf2iH80Q6po1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu')"
      ],
      "metadata": {
        "id": "XUxhRB4gyr10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(5) MaxPool2D Layer"
      ],
      "metadata": {
        "id": "YypjtCBX6skY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same')"
      ],
      "metadata": {
        "id": "MVshFnDNy1wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [3] RNN Layers"
      ],
      "metadata": {
        "id": "59z3Tjq7ZQ6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(6) SimpleRNN Layer"
      ],
      "metadata": {
        "id": "OAYV8IVboZ0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.SimpleRNN(units=300)"
      ],
      "metadata": {
        "id": "Us-a2CvxoYWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3차원 출력\n",
        "    # 단어의 개수(T) 등 시계열 벡터를 출력할지\n",
        "return_sequences=True\n",
        "\n",
        "# 마지막 결과값 출력\n",
        "return_state=True"
      ],
      "metadata": {
        "id": "iqZc5RsWos0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(7) LSTM(Long short Term Memory) Layer"
      ],
      "metadata": {
        "id": "b2rVRFaZpVjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.LSTM(units=300)"
      ],
      "metadata": {
        "id": "6-zQaKWXpVz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(8) Embedding Layer"
      ],
      "metadata": {
        "id": "fsc6DfP6ZUO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length=max_length)"
      ],
      "metadata": {
        "id": "q7ObMDUTZoAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [04] Model Compile"
      ],
      "metadata": {
        "id": "UNcAyCF9mUpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## [04] Model Compile"
      ],
      "metadata": {
        "id": "iOHKXCRsiTPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compile of Linear Regression\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "hRyHVkGNnDks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compile of Binary Classification\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "-Zfeq0ybmkbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compile of Multi Classification\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "oIdpvhdcnkNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compile of Multi Classification without One_hot encording\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "X2J0x6lt2NzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer='adam'"
      ],
      "metadata": {
        "id": "v3QV6oELc8SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [05] Model Training"
      ],
      "metadata": {
        "id": "OB_EquWi0NFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## [05] Model Training"
      ],
      "metadata": {
        "id": "mnacK-JM6GhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size = 32,\n",
        "    epochs=500,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "rFDJ9TYPQD6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit input\n",
        "validation_split=0.2"
      ],
      "metadata": {
        "id": "Taiq49ghIygD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [Callback](https://https://jins-sw.tistory.com/27)"
      ],
      "metadata": {
        "id": "9tLgrJHlDhZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback class implement\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self,epoch,logs={}):\n",
        "        if(logs.get('accuracy') > 0.87):\n",
        "            self.model.stop_training = True\n",
        "            print('\\n>>>',epoch,',',{logs.get('accuracy')})\n",
        "callbacks = MyCallback()"
      ],
      "metadata": {
        "id": "V0Rnhah10Veg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback input\n",
        "callbacks=[callbacks]"
      ],
      "metadata": {
        "id": "BVb9yxQE1ENr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [06] History Visualization"
      ],
      "metadata": {
        "id": "LFpj7JJGP6H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## [06] History Visualization"
      ],
      "metadata": {
        "id": "d5mTpw7rhqBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [1] Loss"
      ],
      "metadata": {
        "id": "aMI6CpS-vwqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Loss\n",
        "plot_count = 1\n",
        "\n",
        "epoch_count = range(plot_count, len(history.history['loss']) + 1)\n",
        "y_plot = history.history['loss'][plot_count-1:len(history.history['loss']) + 1]\n",
        "\n",
        "plt.plot(epoch_count,y_plot, 'r-')\n",
        "plt.legend(['Training Loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NiCMD8BiRKQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# History of Loss\n",
        "print(history.history.keys())\n",
        "print(history.history['loss'][-1])"
      ],
      "metadata": {
        "id": "jZjwFkvWQJhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate of Linear Regression : RMSE\n",
        "print(f'MSE = {model.evaluate(x_test,y_test):0.4f}')\n",
        "rmse = np.sqrt(model.evaluate(x_test,y_test))\n",
        "print(f'RMSE = {rmse:0.4f}')"
      ],
      "metadata": {
        "id": "3CjreGBE_npO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [2] Accuracy"
      ],
      "metadata": {
        "id": "DpA7RMcMvzVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of Accuracy\n",
        "epoch_count = range(1, len(history.history['accuracy']) + 1)\n",
        "plt.plot(epoch_count, history.history['accuracy'], 'r-')\n",
        "plt.legend(['Training accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LoGoPI10tZ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# History of Accuracy\n",
        "print(history.history.keys())\n",
        "print(history.history['accuracy'][-1])"
      ],
      "metadata": {
        "id": "ErPhzKxZvpXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "id": "2xczkMeaRHae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### [3] History Lookup"
      ],
      "metadata": {
        "id": "nDmfZMtuhjjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['loss']\n",
        "history.history['val_loss']\n",
        "history.history['accuracy']\n",
        "history.history['val_accuracy']"
      ],
      "metadata": {
        "id": "oxAguO-qhhMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [07] Predict"
      ],
      "metadata": {
        "id": "x_Jnh4QNTGFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## [07] Predict"
      ],
      "metadata": {
        "id": "h31TaVZF60F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "preds = model.predict(x_data)\n",
        "np.round(preds)\n",
        "# 반올림해서 이진분류"
      ],
      "metadata": {
        "id": "A5oyS31ZTY6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Note: The formula below is not an exact calculation formula."
      ],
      "metadata": {
        "id": "swYGVzcr6_Fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# interval estimation with reliability 95%\n",
        "min_preds = preds - 1.96*rmse/np.sqrt(row)\n",
        "max_preds = preds + 1.96*rmse/np.sqrt(row)\n",
        "print(min_preds,max_preds)"
      ],
      "metadata": {
        "id": "31Ax3U5f68jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interval estimation with reliability 99%\n",
        "min_preds = preds - 2.58*rmse/np.sqrt(row)\n",
        "max_preds = preds + 2.58*rmse/np.sqrt(row)\n",
        "print(min_preds,max_preds)"
      ],
      "metadata": {
        "id": "uOFrMa8Q69FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layer implement without keras"
      ],
      "metadata": {
        "id": "dgDxPVjcIX-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class의 개수 설정\n",
        "nb_classes = 10"
      ],
      "metadata": {
        "id": "SZG79VPHSa73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 퍼셉트론(Perceptron) 개수 정하기\n",
        "percep1 = 512\n",
        "percep2 = 512\n",
        "percep3 = 512"
      ],
      "metadata": {
        "id": "-mZcvE6uQz-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer 1 : Hidden Layer\n",
        "\n",
        "# Weight & Bias\n",
        "W1 = tf.Variable(tf.random.normal([784,percep1]), name='weight1')\n",
        "b1 = tf.Variable(tf.random.normal([percep1]), name='bias1')\n",
        "\n",
        "def layer1(X):\n",
        "    return  tf.nn.relu(tf.matmul(X,W1) + b1 )"
      ],
      "metadata": {
        "id": "BFCdFKfWIgsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer 2 : Hidden Layer\n",
        "\n",
        "# Weight & Bias\n",
        "W2 = tf.Variable(tf.random.normal([percep1,percep2]), name='weight2')\n",
        "b2 = tf.Variable(tf.random.normal([percep2]), name='bias2')\n",
        "\n",
        "def layer2(X):\n",
        "    return  tf.nn.relu(tf.matmul(layer1(X),W2) + b2 )"
      ],
      "metadata": {
        "id": "j3t39OrhQb6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer 3 : Hidden Layer\n",
        "\n",
        "# Weight & Bias\n",
        "W3 = tf.Variable(tf.random.normal([percep2,percep3]), name='weight3')\n",
        "b3 = tf.Variable(tf.random.normal([percep3]), name='bias3')\n",
        "\n",
        "def layer3(X):\n",
        "    return  tf.nn.relu(tf.matmul(layer2(X),W3) + b3 )"
      ],
      "metadata": {
        "id": "XfppceKbQdg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer 4 : Output Layer\n",
        "\n",
        "# Weight & Bias\n",
        "W4 = tf.Variable(tf.random.normal([percep3,nb_classes]), name='weight4')\n",
        "b4 = tf.Variable(tf.random.normal([nb_classes]), name='bias4')\n",
        "\n",
        "# inner product\n",
        "def logits(X):\n",
        "    return tf.matmul(layer3(X),W4) + b4\n",
        "\n",
        "# Softmax function\n",
        "def hypothesis(X):\n",
        "    return tf.nn.softmax(logits(X))"
      ],
      "metadata": {
        "id": "54nIu49XQfM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "def hypothesis(X) :\n",
        "    return tf.matmul(layer2(X),W3) + b3"
      ],
      "metadata": {
        "id": "Ny2nTfOkTEdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set optimizer"
      ],
      "metadata": {
        "id": "4NrRI1WRhsuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)"
      ],
      "metadata": {
        "id": "xTl-1GNFH9eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Model with batch"
      ],
      "metadata": {
        "id": "3ofQs7YHTerj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 시작\n",
        "\n",
        "# batch 사이즈로 나누어 학습, 효율적이며 시간 단축\n",
        "training_epoch =15\n",
        "batch_size = 600\n",
        "\n",
        "print('*'*5,'Start Learnimg!!')\n",
        "for epoch in range(training_epoch):\n",
        "\n",
        "    avg_cost = 0\n",
        "\n",
        "    # 100 = 60,000 / 600\n",
        "    total_batch = int(x_train.shape[0]/batch_size)\n",
        "    for k in range(total_batch): # 100 회\n",
        "        batch_xs = x_train[k*batch_size:(1+k)*batch_size]\n",
        "        batch_ys = Y_one_hot[k*batch_size:(1+k)*batch_size]\n",
        "\n",
        "        # 비용 함수\n",
        "        def cost_func_batch():\n",
        "            cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits(batch_xs),\n",
        "                                                         labels=batch_ys)\n",
        "                                                            # y_train 에서 Y_one_hot 으로\n",
        "            cost = tf.reduce_mean(cost_i)\n",
        "            return cost\n",
        "\n",
        "        # 학습 시작\n",
        "        optimizer.minimize(cost_func_batch,var_list=[W1,W2,W3,W4,b1,b2,b3,b4])\n",
        "\n",
        "\n",
        "        # 누적 비용\n",
        "        avg_cost += cost_func_batch().numpy()/total_batch\n",
        "    print('Epoch:','%04d'%(epoch + 1),'cost:','{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('*'*5,'Learnimg Finished!!')"
      ],
      "metadata": {
        "id": "9Wq9r9ICTufk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 회귀 계수 출력\n",
        "print('Weight =', W.numpy())\n",
        "print('Bias =', b.numpy())"
      ],
      "metadata": {
        "id": "acc5wdwMj0_K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}